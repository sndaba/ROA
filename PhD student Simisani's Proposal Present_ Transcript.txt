PhD student Simisani's Proposal Presentation on 21st Nov 2024, Thursday at 8am - 9am 
Thu, 21 Nov 2024

0:00 - Rajalakshmi Selvaraj yeah what do you know coming later yeah yeah sometimes people will join sometimes people won't join but if the examiner join it's fine I'm doing on that oh all right as long as you're prepared is it I think so but do you know semi sunny they're going to give only 20 minutes time okay just you can take extra two to three minutes not much more Make sure that you are going to complete within the timeline Okay, then after that it's a question from the audience as well as from the examiner also, that's a procedure here. Oh Okay I Thought of the rest that I should talk to you, but I was not feeling well I went to the clinic. I took the injection That's why today morning I'm running running to Oh, no, I hope it's not COVID. It's not COVID. Oh, OK. It's not feeling well.

0:57 - Simisani Ndaba I understand. Because of the climate.

0:59 - Rajalakshmi Selvaraj You know, hot, cold, hot, cold. It's killing us.

1:02 - Simisani Ndaba Literally, it is killing.

1:04 - Rajalakshmi Selvaraj Say, it's not good. Shabba.

1:06 - Simisani Ndaba It's really bad like that. Suddenly, it is very hot.

1:10 - Rajalakshmi Selvaraj Suddenly, it is cold, raining. And the kids are there going to the school. They are catching from there, and they are spreading it Oh my goodness, yes.

1:21 - Simisani Ndaba It's not good when it's like that.

1:25 - Rajalakshmi Selvaraj In the school, they are not giving the proper care to the student also. They are not switching on anything.

1:35 - Simisani Ndaba Oh, man. That's bad. They will join a little bit late, late, late. Oh, right.

1:43 - Rajalakshmi Selvaraj They usually come 10 minutes or five minutes later.

1:48 - Simisani Ndaba You know them.

1:49 - Rajalakshmi Selvaraj Because I have to admit everyone.

1:51 - Simisani Ndaba That's the reason I joined, so that I can admit.

1:54 - Rajalakshmi Selvaraj Some people, they will ask to admit when I'm admitting. If they are not in the Houston network, if they are outside, they ask us to admit.

2:03 - Simisani Ndaba That's right.

2:03 - Rajalakshmi Selvaraj That function, before you join, it has to be, someone will have to allow you to admit.

2:09 - Simisani Ndaba I just started sharing my screen. Can you see it? Yeah, yeah, I can see. I can see.

2:16 - Rajalakshmi Selvaraj All right. You can see, now these people have started. I'm waiting for the examiner to join. Oh, OK. All right. The thing with sharing the entire screen, I can't see anyone.

2:33 - Simisani Ndaba I can't see you. Oh, oh, oh, fine, fine.

2:37 - Rajalakshmi Selvaraj No problem. OK.

2:39 - Simisani Ndaba But anyway, I'm informing, no?

2:42 - Rajalakshmi Selvaraj That's good. Because I'm waiting for the examiner. Two examiners. How many are coming?

2:53 - Simisani Ndaba Two.

2:54 - Rajalakshmi Selvaraj Sorry, two examiners. Yeah, Mama. It's a two examiner.

3:02 - Unidentified Speaker Two.

3:02 - Simisani Ndaba Two. Two examiners is two examiners.

3:07 - Unidentified Speaker Right.

3:20 - Rajalakshmi Selvaraj All right.

4:03 - Simisani Ndaba let me check the examiner is there or not once again let me go you one examiner joined actually I checked with the other examiner she's trying to join the Yeah, I think Apruf joined and Dr.

6:16 - Rajalakshmi Selvaraj Carbo also joined, no problem. So shall we start? Because almost it's five minutes late. Simisani, are you ready, mama?

6:31 - Simisani Ndaba Simisani, can you hear me?

6:35 - Unidentified Speaker Simisani? Simisani? Simisani?

6:43 - Simisani Ndaba What happened to the skin? Simisani? Okay. Simisani, can you hear me? No, your voice is breaking. Is it only for me?

7:37 - Rajalakshmi Selvaraj There is some strange sound.

7:44 - Irina Zlotnikova It's like music, background music. Exactly proof. Simisani, can you hear me now?

7:50 - Rajalakshmi Selvaraj I hear you now, ma'am. Can you hear me?

7:55 - Simisani Ndaba Yeah, I can hear you now.

7:57 - Rajalakshmi Selvaraj Shall we start? Are you ready? Okay. Okay. Yeah, please. Yes, I'm ready. Yeah, just I will give the introduction about you. Good morning. Colleagues and good morning students. Today, a PhD student, her name is Simisani. She's going to give the proposal presentation. Simisani, you have given only 20 minutes time. Before that time, you have to, or on, or before that time, you can finish your presentation. And your examiner is Professor Arina and Dr. Kabo. They are your examiner. OK? OK. After the 20 minutes, first, I will give the chance students to ask the question, then if there is no question from the student or if they finish the questions, then I will give it to the examiner to ask the question based on your proposal and the presentation also. It's fine? Shall we start? Okay.

8:57 - Simisani Ndaba Do you have any doubts to ask? Do you have any doubts to ask? No doubts, just that if my slides move, if they don't move. Just let me know.

9:08 - Rajalakshmi Selvaraj And if you can't hear me, just let me know. Can you try now? Can you try now?

9:16 - Simisani Ndaba Just move. Just move to the next slide. Let me see.

9:21 - Rajalakshmi Selvaraj No, it's not moving. It's not moving.

9:24 - Simisani Ndaba It's not moving.

9:26 - Rajalakshmi Selvaraj Yeah, now it's moving. It's moving. Yeah. Oh, everything is perfect. Okay. Yeah, now it's just let me know during yeah sure sure okay I don't want to interrupt you also that's why I'm checking it it before you start the presentation okay now but please do interrupt okay no problem no problem

9:48 - Simisani Ndaba it's fine now you can start all right thank you professor hi everyone as professor savaraj said I'm Simisani Ndaba and I'll be presenting my proposal for the degree of Dr. Philosophy, my supervisors, Professor Selvaraj and Dr. Sromani. The title of my research is Rhino Optimization Algorithm for Hyperparameter Optimization in Machine Learning Models. So what we'll be going through the talk is an introduction to the problem, the related work surrounding optimization, the problem statement based from the related work, the solution of the problem, which is the Rhino Optimization Algorithm, the specific objective as well as the general objectives. We'll also look at the research questions the study will be answering, contributions slash justification slash significance, and we'll also go through the methodology of how the Rhino Optimizer works. So before we talk about optimization, we need to understand what hyperparameters are. These are the external configuration settings that are predefined outside the machine learning model. So they need to be set before the machine model can operate. Different machine learning models have different parameters as well as hyperparameters. So the difference between the parameters and hyperparameters is that parameters are internal, are inside the machine learning models that can be updated and are part of the problem that needs to be solved. As in, if a machine learning model is tuned, the parameter will be tuned as well. So if we look at the example under neural weights in the neural network, The mathematical expression there is what we call an objective function that optimization tasks use. So the x to the power of 2 and y to the power of 2 are called parameters. They're within the objective function that has to be trained. Tuning parameters and machine learning models can be framed or seen as optimization problems. That is, when you're tuning parameters, the navigation of looking for combined hyperparameters of what can be seen as optimization problems. So algorithms that work on optimization problems are called optimization algorithms. Traditionally, we've been using grid, random, Bayesian search, gradients, which use probabilistic methods and automated models for optimizing algorithms. The problem with these traditional algorithms is that they don't usually find, they always stick to a local optima, as in they have a problem searching for a good combination within a large hyperparameter search space. So over the years, metaheuristic algorithms have been used because they're able to, what we call, converge between looking for a position that has a good combination and looking within or around a hyperparameter search space. So these metaheuristic algorithms, these methods inspired by nature phenomenon, as in they get their methods inspired by biological systems, physical systems, behaviors of animals. These are general all-purpose optimization tasks which are used within the optimization challenges within the large search space, search spaces. So the algorithms that have been created under the metaheuristic algorithms generate what we called near optimal, as in quasi solutions, as in at the time of it, they can solve the convergence problem. That's why more algorithms need to be created. And a good example of an optimization problem, as well as what we call a nature-inspired problem, is the movie The Wild Robot. Our protagonist, Robot, crash lands on an island and tries to climb up a mountain to get away from a river, a flood that's coming, and it gets its inspiration how to climb it from a crab it sees. So this is a perfect example of an optimization problem. The movie also thoroughly explains how machine learning models work. If you haven't seen it, it's a brilliant movie, and I highly suggest you watch it as a computer scientist. So metaheuristic algorithms are divided into solution-based as well as population-based. Under the population-based, there's evolution, swarm intelligence, physical and miscellaneous. The related works that we're going to be seeing use some of these algorithms and actually have created these optimizers. The following are divided into scalable related works, as in they use a large and diverse data set in order to scale or in order to work on the optimizers. As we can see under the BO which stands for bio-inspired algorithms. They've gotten their inspiration from leopards, from hawks, from zebras, from ducks, and they've gotten the herd behavior, hunting, prey identification, and searching for food. As we can see at the top, the rhino herd actually gets its method from the social group collective performance of animals. And as we can see, which is very different from the rhino-optimized we'll be looking at later. The machine learning models are not really used because optimizers are not. There are different kinds of optimizing problems. They're not only used to tune hyperparameters. There's what we call the famous traveling salesman, which looks for the shortest route to reach a destination. That may be coming in a company. As well as energy reduction to find how people best can reduce the energies. The metrics they use are called benchmark functions. They don't really use the accuracy or the F1 or the recall because they're testing performance of the optimizers. So the benchmarks, what they have are called optimal functions, which are what the optimizers have to set to. The benchmarks have the standard that the algorithms need to achieve. Other related works that use large scalable data sets, which are diverse, get inspiration from puffer fish, the walrus, which get the natural behavior from the feeding, the hunting. As you can see, they don't use the machine learning models. Various applications are used on optimizers, not exactly prediction for machine learning. And the CEC 2017, what we call, is what the name of the benchmark functions that they use. More related works use non-scalable, as in they don't use a large diverse data set. And these related works use the get inspiration from bats, from herds, from horses, from The Tasmanian devil, they get different kinds of methods to inspire their behavior. The bat echolocation uses the bat method when it sends a noise. And the reflection from the echo or from an object is what they can feel is around them and near them. And that's exactly what the method, the optimization uses. It tries to find the nearest hyperparameters and the combinations. For this related work, it used a classification which needed a machine learning model, which is a convolutional neural network, and used the accuracy to test its classification model. Others have gotten inspiration from hippopotamuses, hybrid, eagle, and such algorithms. So they can use two different animal behaviors at the same time, which are called hybrid optimizers. They use the crow and the beetle. And different inspired behaviors are from the user searching. They use the beetle antennas to search for food. This time we can see some of these models have what they call integrated the machine learning models with the optimizers, which they also in turn apply them to optimization tasks. And they've continued using benchmark data sets. And they've also used what they call a minimum error rate to see how fast they can convergence, as in looking for a combined hyperparameter works. But what we have seen is that the problem is looking for a combined set of hyperparameters to be used for their optimization. And also, another problem is for the non-scalable, they have a problem with a diverse large data set. That's why the problem statement states that hyperparameter algorithms often fail to efficiently identify optimal solutions within expansive and complex search spaces, particularly in large dimensional contexts. The ROA, which is the solution inspired by RINO, food search foraging and adaptability behaviors, addresses enhancing search space navigation and improving convergence rates, creates a flexible balance between exploration and exploitation phases. The balance between Exploration and exploitation is the main problem in optimization, within optimization tasks. So looking at our solution, which is called the Rhino Optimization Algorithm, uses the behavior of the foraging behavior of rhinos, as well as the adaptability to when they find a good, actually good for an optimization tasks, because the ability to change governs the balance between exploration and exploitation. As you can see on top, the rhino looking for food is what we call, is what considered exploration within the search space. The exploitation phase for the rhinos is when they find a good water source and within the hyperparameter search space works on a good combination that have found. So fun facts about rhinos is that they land mammals, they're solitary animals, they don't necessarily hunt together. They prefer to stick to the customary they prefer to stick to the areas they prefer and they find interesting, not interesting, but where they find a good food source, which is related to, which is actually the inspiration for the exploitation phase, which is an exact copy from their behavior. And just like elephants, they follow wild trails with little to no vegetation. And another fun fact about rhinos is that a black rhino and a white are both actually gray. They were just mislabeled a long time ago. There are five species in the world, and they're currently on the brink of extinction. So the general objective of this solution is to develop a new bio-inspired algorithm, the ROA, based on the food foraging, search, and adaptive behaviors of rhinos to overcome the short of existing hyperparameter optimizations. The food forging, the specific objectives, if I can just zoom in for this. If you can look at specific objective number one, the first one is to formulate a model to model the behavior of the rhino, to apply the optimizer to different machine learning models, specifically the support vector and different neural networks, to evaluate the scalability as in whether it used in a diverse, large data set, to analyze the convergence rate, as in how quickly can it find a near optimal solution, as in how quickly can it find a suitable combination of hyperparameters, as well as compare the performance with the hyperparameter algorithms we looked at before in the literature review. The research questions, if we can zoom in again. The first one for the study to answer is, what are the specific factors influencing the effectiveness of the optimizer in hyperparameter tuning compared to other algorithms? How do the exploration and exploitation phases modeled after the rhino behavior contribute to the performance in the optimization tasks? To what extent does the rhino optimizer improve the convergence rate in complex machine learning algorithms like the neural networks and the support and how does the rhino optimizer perform across different data sets, and what is the impact of varying hyperparameter settings on the performance of the rhino optimizer, and how best can we inform best practices for algorithm tuning. The contribution to this study, if I can zoom in one by one, is that the behavior, one contribution in significance is that the behavior is taken from the rhino foraging and adaptability of how the rhino looks for food. And this combination has never been used before from the literature review that we've looked at and from other optimizers to the bio-inspired optimization algorithm, which in turn can be used not only in hyperparameter optimization, but can be broadly used and scalability in optimization tasks, as in the traveling salesman, energy, and that's the aim, and that is the hope that the Rhino Optimizer sets to achieve. It also addresses the trade-off challenge between global and local searches, as in looking for position in the hyperparameter space that can actually look for good combination, and also looking around the hyperparameter space. So looking at exactly how the optimizer can achieve this. We can start looking at the flowchart. We can start at within the hyperparameter space. It initiates random generator population within the hyperparameter space. And it also releases hyperparameters from the support vector machine. Learning model as well as the neural network model. Within the positions are checked to see the fitness, whether the position they're in, in the hyperparameter space is a good combination of hyperparameters to be used. And if they are, I don't know if I can, okay, I can move it. And if the position does create a good combination, it asks whether it needs to do any more exploration or whether it doesn't have to. But if it does, it needs to go out into the hyperspace again to look for different positions. And if it does find a good position, it goes back to see whether the fitness is okay. But otherwise, if it doesn't, it concentrates on that area, that position, the in and the hyperparameter space. And within that location where they're working on improving, that space where the combined hybrid parameters are. The memory is the optimizer, what the Rhino optimizer does, it memorizes or updates its memory to that location to see the location of where it can produce a good combination of hyperparameters, the space location, and upon that, after a few iterations of the different locations where it can find, it needs to check whether if it's reached the maximum iterations that it can find within the search space, or whether an optimal solution has been found. If it hasn't, it has to go back for fitness to see whether it can go through exploration process again, and if it has, the best solutions are identified, and the combination of hyperparameters have been set and can be carried out to the machine learning model. In order to test the Rhino optimizer, because it's using the optimizer for the hyperparameter task, it needs to evaluate how the machine learning models work after the hyperparameters are optimized. If you go in detail, first I have to find a data set which is standardized that the other related works have used. Before we process it, we have to normalize it, standardize it, then we apply the NIST pre-processing, handling missing values, encoding the category, and then split it into training and testing data sets. Then we define the support vector machine learning model as well as the neural network model. The reason why the support vector and the neural networks have been chosen is because they have intricate hyperparameters that are difficult to tune and need to be tuned because they work within a large dimensional space or a large hyperparameter space. So after doing this, we then initiate the Rhino Optimizer. As we saw in the method, it releases a predefined number of population size of hyperparameters, as well as sending agents within process begins, as in it looks for a good combination of hyperparameters, hyperparameters respective of the machine learning models. It figures whether a good combination within the location is good, and they select the good combination after number of iterations. Training the optimized hyperparameters means getting the best combination for the support vector model and the neural networks. And these optimized hyperparameters will be used during the training of the support, during the training of the machine learning models. And the machine learning models will be analyzed. They perform precision and recall for both machine learning models, as well as a comparative analysis of before and after the machine learning models. Learning models worked before the optimization, and a comparative analysis will also be made to see the convergence rate and speed compared to other bio-inspired algorithms. So convergence, how it looks, how it does, in which position in the hyperparameter space it does this.

29:53 - Simisani Ndaba Hello, can you hear me? Yes, I hear you.

29:57 - Rajalakshmi Selvaraj Yes, I finished.

29:59 - Simisani Ndaba You are finished. Okay.

30:01 - Rajalakshmi Selvaraj So thank you for your presentation. Now I'm inviting our student to ask the question to you. Students, the floor is yours. Students, Masters and PhD students, the floor is yours.

30:20 - Simisani Ndaba Yacobo, please go ahead.

30:22 - Rajalakshmi Selvaraj Thank you for the brilliant presentation.

30:26 - KABO CLIFFORD BHENDE I'm doing something around machine learning and I realise that it's not just limited to your dataset. You can also apply it based animal behavior. So you're just, you're just taking me to a different portal where you can look at machine learning at a natural level using the nature we have to study the traits and then convert them. I think your topic would correlate something with something around, around robotics. So you've just enlightened me on that aspects of just applying machine learning in a different environment. So thank you to that. Thank you.

31:10 - Simisani Ndaba All right, thank you. Good luck in your study. Kabo, are you done?

31:26 - Rajalakshmi Selvaraj Kabo?

31:27 - Unidentified Speaker Anyone?

31:28 - Simisani Ndaba Students? Then shall I invite the examiner? Okay, not just yet, maybe if the others want to write in the chat, if they can't use their mics. Yeah, you can do it in the chat also students, we don't have any problem on that.

31:49 - Rajalakshmi Selvaraj If you want to do if you want to ask any questions, you can write it in the chat so that Simisani can answer for that. So meantime, I didn't get any question from the students also so that I mean waiting the examiner. So once the examiner finished also you can raise the question there is no problem on that In the meantime, you can think and check with Simisani also. Okay, now I'm inviting Prof. Arina to ask the question to the student.

32:18 - Irina Zlotnikova Prof., the floor is yours. Okay, yes. Thank you for your presentation. I should say that your presentation is much better than your proposal. I make my comments within the proposal because although content is important. It's also important to follow the guidelines, to follow the provided template. Especially it is important when you submit a paper to a journal, because in this case, you need to follow the guidelines adopted by this journal. So there are some minor issues in relation to your proposal. And I commented regarding those minor issues. In your proposal. The proposal will be sent to you immediately after the presentation. I want to confirm something. The topic seems to be very interesting and you seem to be quite knowledgeable of the area where you are going to do your research. But I just want you to confirm for me what is the main outcome, what is the main contribution of proposed research. In one sentence only, what is the main contribution of your research?

33:40 - Simisani Ndaba I would say the main contribution would be to create a new or novel bio-inspired algorithm that uses the rhino behavior in order to address the of between exploration and exploitation in the hyperparameter search space.

34:05 - Irina Zlotnikova Okay, so this proposed algorithm is completely new and nobody has done anything like this before. Yes, that's true. So the entire algorithm will be your contribution. Okay. Yes, it will. What are the possible applications of the proposed algorithm?

34:30 - Simisani Ndaba The algorithm is supposed to be applied on hyperparameter optimization. That's the main application it will be used on. Because as an optimizer, it needs to search for a good combination of hyperparameters. So that will be the main application. It will be looking for hyperparameters. It needs to use machine learning models. And that's where the hyperparameters and parameters are. So it will be, I would say the application is within hyperparameter optimization.

35:13 - Irina Zlotnikova Can you explain some tasks, specific tasks that your algorithm can be Specific tasks, you mean apart from hyperparameter optimization? Yes, this is the general application, but can you please elaborate what could be proposed directions for further research if someone wants to apply your algorithm? Oh, okay.

35:44 - Simisani Ndaba Because this is...

35:46 - Irina Zlotnikova Maybe it is also applicable to practical tasks? Oh, OK.

35:52 - Unidentified Speaker Applicable to?

35:53 - Simisani Ndaba I think because this is an optimizer, it can be applied to what they call portfolio optimization, which is in accounts, they look for risk balancing and how to reduce the risk in portfolio. Another application can be used in finding the shortest which is a GPS system. So there's the navigation system. There's also engineering design. Those are the ones that I can think of right now. But because it's an optimizer, it's linked to machine learning, which is prediction modeling. And not only will it be applied to these optimization tasks, it will be added within a package, or I'm hoping it can be added to a Python package, like with the grid search, random search, and where the other metaheuristic algorithms are found, or can be found.

37:05 - Irina Zlotnikova Now those are the questions from me. Now I'm going to comment, and I said I wouldn't focus on minor issues, all minor issues. I commented on minor issues in your proposal. But what I cannot call minor is that your specific objectives are too long and sophisticated. And those not only deliver the main outcomes, the results that you intend to receive following those objectives, but also the methodology. And it should not be there. Objectives should only deliver the main result and not the way to get this result. So you need to separate results, which is objectives, and methodology, and make your specific objectives shorter and simpler. Then another comment is in regard to methodology. The methodology is not directly related to the objectives. As I said, you should reformulate, rephrase your objectives and make them simpler. And the same applies to the general objectives. There is too much information regarding the general objective. So each objectives must be easily understood by the readers. And then in methodology, you take a general, you take specific objectives. So each specific objective contributes to the achievement of a general objective. And then in methodology, you take every specific objective, and you demonstrate how you're going to achieve this objective. It's a good thing also to include a table which links your specific objectives, research questions, outcomes of each objective, and methodology to achieve. So first methodology, then outcomes or results of each objective. So this way, it is completely clear how you are going to achieve each specific objective and all of them contributing to the general objective. So again, it's a question of restructuring your proposal and for your future work, like submitting, producing and submitting journal papers and also your dissertation. You need to structure your work in a different way. More obvious way. Okay, I can see that Dr Mafa has raised a hand, although I'm not done yet. Okay, so the recommendation would be to check the existing proposals. Maybe your supervisors can help you with providing and proposals, you can follow and you can adopt the structure from those proposals. Okay, I suppose this is it.

40:43 - Rajalakshmi Selvaraj Thank you, Prof. Dr. Mafa. Dr. Mafa.

40:54 - Rodnie Kgalemelo Mafa Oh, sorry. My mic was muted. Good morning. Can you hear me? Yeah, we can. Prof. Irina, I wasn't raising your hand while you were speaking. I wanted to be the next person after you. Not that I was saying there's something wrong. All right. Thank you. Yeah, thank you for a well-thought presentation. Then I didn't hear you quite well so I've got only three additions or should I say comments that I'd like to post to you if you can't answer them now you can you can also look into them in order to shape your your study to be fulfilling more fulfilling right in the context of machine learning In the context of machine learning, hyperparameter optimization is critical for enhancing model performance. That's right, I get it. Yes, hyperparameter optimization is critical for enhancing model performance. So, I would like you to elaborate on the theoretical and practical differences. Right? Theoretical and practical differences between grid tech. I know you talked about them. But I want the theoretical and practical difference between grid search, random search, and Bayesian optimization as techniques for hyper-parameter tuning. Additionally, I would like you to look more into how do these models scale with increasing model complexity and dimension. How do these methods scale with increasing model complexity and dimensionality? And also, you should look into, or rather say, you should discuss any domain-specific adaptations, such as those relevant to ecological modeling or rhino-related datasets. Mm-hmm.

43:14 - Unidentified Speaker Yes.

43:15 - Rodnie Kgalemelo Mafa Oh, should I answer them now? Oh, yes.

43:19 - Simisani Ndaba As for the grid, random, and gradient, they do have different methods. The gradient uses a probabilistic method. The thing with the random and the grid search is that what they do is that they could have a finite set of hyperbolic hyperparameters within a hyperparameter space. And with the grid search, it has to find, it just combines the hyperparameters that are there. And with the random search, it does a random combination until it finds a good combination. But most of the hyper, the grid and the random search are not necessarily used, or they're not, not that they're used, but they're not very good hyper high dimensional spaces. That's why other algorithms are used within the high dimensional space. The Bayesian, another one would be the Bayesian search, which is also not thoroughly used in high dimensional. They're not used exactly in large data sets that are diverse. That's for grid random and gradient. As for the methods that, whether these methods are good in complexities, no, they're not necessarily good in high dimensional because other algorithms have been developed for large hyper search spaces and the domain specific, domain specific, domain specific areas where the rhino can be used in, can be used, can potentially be used in optimization. Yes, sir.

45:07 - Rodnie Kgalemelo Mafa I don't want us to make it a dialogue, considering the fact that we have a general staff meeting at 0900. I can hear you answering there. But what I would say is I would like you to look into them. Oh, OK. And try to see if they fit well. I don't want questions as they are not good, these methods, what, what. Look into them and try to expand more on them so that your study could be more fitting. Because the choice of the method depends on the computational resources available and the dimensionality of the parameter space and the domain-specific requirements of that particular model which you will be using, right? So my point was really for you to look into and let's not make it a dialogue. And also look into the Bayesian optimization, how advantageous it is and it will be in your study. Thank you for that.

46:20 - Rajalakshmi Selvaraj Okay. Thank you, Doc. Now I'm inviting another examiner, Dr. Kabo. Sorry, Kabo.

46:28 - Kabo Nkabiti Thank you. Thank you, Professor Raj. Thank you, Dr. Mafa. And thank you, Professor Irina, for your contribution in this presentation. Good morning, Simisani. Hello, sir. How are you?

46:43 - Simisani Ndaba All right.

46:44 - Kabo Nkabiti I would like to applaud you for your wonderful presentation. You did very well. You handled your presentation very well. It shows that you are really knowledgeable in your area, and you know a lot of things in this particular area.

47:05 - Simisani Ndaba Not really.

47:06 - Kabo Nkabiti Yeah, yeah, it's part of learning. But it shows that you have invested a lot of time to learn about different concepts in this particular area. So I'll applaud you for that. I have a few questions. I have a few questions. Most of the comments that Professor Irina did mention, I wanted to talk about that, but she's already covered those, but I only have a few questions. I don't know if I should ask all the questions and you answer them after I ask them, or I should ask one question, then you answer, then another question, then you answer, or I should just ask all the questions and you answer all the questions at the same time.

47:47 - Simisani Ndaba I think I can ask all the, I can try and answer all of them at the same time because the professor has a- Also because we don't have much time.

47:56 - Kabo Nkabiti aforementioned that we have a meeting at nine. My first question is, why have you, for testing your algorithm, why have you chosen to use the data sets from UCI and MNST as you have shown in your proposal? And the other question, that is the first question. And then the second question is that how does does the Rhino optimization algorithm ensure or does not overfit specific problem domains or datasets model overfitting? That is the second question. And then the third question is that are there any plans to test the Rhino optimization algorithm against newly emerging optimization, such as zebra optimization or dark swarm algorithm? And then that is my third question. And then the fourth question is, could there be scalability of Lionel optimization algorithm? Can it be demonstrated using extremely high dimensional data sets or real world engineering problems? I think that question, Dr. Mafo also touched And Professor Irina as well touched on that particular question. Could there be a scalability of a Rhino optimization algorithm? Can it be demonstrated using extremely high dimensional data set or real world engineering problems? That is my fourth question. And the last question is, is there a comparative analysis of a Rhino optimization algorithm algorithm with non-bio-inspired method such as generic algorithms or reinforcement learning techniques. So those are my questions. You can go through the questions. Okay, I'm going to start with the last question.

50:01 - Simisani Ndaba I'm going to start with the last one to the first one. As for comparing the analysis with non-bio-inspired, I actually didn't think about that because the Rhino Optimizer is a bio-inspired, I thought of comparing it with other bio-inspired algorithms. But I think I can compare it to maybe the Bayesian as Mr. Mafa had suggested. So I think I will add it to the... Dr. Mafa?

50:30 - Kabo Nkabiti I was just correcting you, Dr. Mafa, not Mr. Mafa. Oh, sorry. Yes, Dr. Mafa. Yes, as Dr.

50:38 - Simisani Ndaba Mafa was saying, when he suggested I look into the Bayesian search, I think I can compare to compare the rhino optimizer to the Bayesian and other traditional optimizers. And as for the rhino optimizer being scalable, I think after it has been created, the plan is to test it with a large diverse data set, which has a high dimensional space. So that is the plan. And it is supposed to be adaptable and scalable. And as for it, if there are any plans to test it, with the other metaheuristic algorithms. That is also the part of the comparable analysis. And as for the RINO optimizer, avoiding overfitting of domains and datasets, that is also part of its method. Its method to look for a good combination within the hyperparameter space and its adaptability to change the, to find the best fitting combinations is part of its overfitting within the data sets. And the last one is, well, not the last one, the first one that you asked for using the data sets, the MSTN and the USI. The thing is that when I was preparing the proposal, after doing some thorough reading, I could see that the optimizer could be used in, can be actually used for not only in the benchmark functions, but the other data sets that I have to look for. Maybe they are within the benchmark functions that are not necessarily contemporary, but they are secondary, as in they could be publicly available.

52:26 - Kabo Nkabiti I hope I've answered your questions. Thank you. Thank you, Simisani, for your answers. I don't have any further comment on that. Thank you for your presentation and well done.

52:43 - Simisani Ndaba Thank you so much, Dr. Kabo. I just have a question for Professor Irina. She talked about how I need to follow a template and a guideline. I just would like some clarification what she means.

52:59 - Irina Zlotnikova Professor? Okay. These are standard rules, although it might not be written anywhere, such as you need to number your sections. It's everywhere in the proposal. I will provide the comments. I didn't want to focus on it now. And typically, your specific objectives should be very simple. So it's a very short sentence or a statement linking each objective to the result. And if you If you provide methodology, it is better if you demonstrate how each of the objectives will be achieved using what exactly research methods. Okay, I see. So if you want to follow the stages instead in your research, instead of following the objectives, then you need to link the stages and the objectives. So you need to show the alignment of the stages in your research and your specific objectives. So in most cases, you can combine stages and objectives by revising objectives. For example, you have a stage number one, and you can link stage number one to the first specific objective.

54:22 - Simisani Ndaba This is what also I advise you.

54:25 - Irina Zlotnikova I don't know if the next step for you would be to produce a literature review paper. There are certain rules, certain guidelines in the journals. So you will need to check what are the guidelines. Here in VIEWS, we follow certain templates. So the recommendation would be to ask your supervisors to provide, let's say, good examples of the proposals previously submitted. And examined by proposals by our PhD students. But I provided more comments in your proposal. So I can notice that some of the sections are not numbered. You don't need to number, for example, abstract. I'm not sure you even have abstract in your proposal. Let me check. Yes, there is an abstract, but it's not to be numbered. Section number one, introduction, it's numbered as four, but in actual fact, this is section one. These are some obvious things. Background is not numbered. Sections within introduction are not numbered. This is what I meant. You might say this is not important, The content is important, but there are cases when papers, actually many cases when papers are rejected by journals because they didn't follow the guidelines. Okay, all right. Thank you so much.

56:09 - Simisani Ndaba I just needed clarification there, and I have to say that I did, I have to admit that I didn't link the objectives with the research questions and with the methodology. I just thought that I was just going to talk about this is the method that I'm doing and I think I will link them.

56:33 - Irina Zlotnikova Thank you so much for that. Because if you if you do not align methodology to your research objectives, you cannot say after completing your research, how are you going to prove that all the objectives that achieved, including the general objective. So you need to link your research methods and stages in your research to your specific objectives to prove that, indeed, each and every objective has been successfully achieved in your research. Thank you so much.

57:09 - Simisani Ndaba I wanted to ask if it's possible if I can switch from information systems to computer science, because seeing that this is a development of an algorithm, I think it would be more suited under computer science. I don't know if there's any administration I can go through to do that.

57:34 - Irina Zlotnikova I don't know if you're asking me, Simisani. Yes, I agree it's more on the computer science side. I don't see any information systems here. If there were applications visible, I asked you applications of the algorithm, practical applications. Yes, it could also qualify as research in informatics, but I don't see it here. Maybe Professor Selvaraj would agree, would be able to advise you.

58:11 - Unidentified Speaker Okay.

58:12 - Simisani Ndaba Thank you, ma'am. Thank you, Prof.

58:16 - Rajalakshmi Selvaraj previously we had a discussion on that also proof that she is supposed to change the program then I enquired with the PG schools also I am going to do that process proof we did it already Simisani we already we have discussed is that you are not related to the information system you are related to the computer science like that yes ma'am okay later I will I will start the process on that all right it's on going little bit okay I can do that later okay any questions from the student any question from our colleagues also student oh everyone is saying that shop I can see that okay I think no more audience as well as from our colleagues also from our department staff it's fine thank you Simisani okay later I will get the comments for actually professor arena will give the comments to you and dr. Carbo also later you will come to know that what is the feedback of this your presentation okay I will communicate to you within another 30 minutes or else tomorrow I will get the phone from them after that I will send forward to you professor I'm closing this meeting. Thank you. Thank you, ma'am. We'll talk. Thank you.

59:43 - Simisani Ndaba Thank you.

59:43 - Rajalakshmi Selvaraj Thank you.